.. _USAGE:

.. _sec:UsingFiPy:

==========
FiPy Usage
==========

To see examples of problems that :term:`FiPy` is capable of solving, you can run
any of the scripts in :mod:`examples`. 

.. note::

   We strongly recommend you proceed through :mod:`examples`, but at 
   the very least work through :mod:`examples.diffusion.mesh1D` to understand 
   the notation and basic concepts of :term:`FiPy`.

We exlusively use either the unix
command line or IPython_ to interact with :term:`FiPy`. The commands in
:mod:`examples` are written with the assumption that they will be executed from
the command line. For instance, from within the main :term:`FiPy` directory, you
can type::

    $ python examples/diffusion/mesh1D.py

A viewer should appear and you should be prompted through a series of
examples.

.. note::

   From within IPython_, you would type::

       >>> run examples/diffusion/mesh1D.py

In order to customize the examples, or to develop your own scripts, some
knowledge of Python syntax is required.  We recommend you familiarize
yourself with the excellent `Python tutorial`_ [PythonTutorial]_ 
or with `Dive Into Python`_ [DiveIntoPython]_.

As you gain experience, you will want to see
:ref:`FAQ-FlagsAndEnvironmentVariables` to learn about flags and 
environment variable that affect :term:`FiPy`.

----------------------------------
Environment and Command Line Flags
----------------------------------

 :term:`FiPy` will select the first viewer that is available
from the list below.  If more than one is installed, specify a viewer
by setting the :envvar:`FIPY_VIEWER` environment variable to either
"``gist``", "``gnuplot``" or "``matplotlib``".

----------
Virtualenv
----------


------------
Testing FiPy
------------

After installation, you can test :term:`FiPy` by executing::

    $ python -c "import fipy; fipy.test()"

From the base directory, you can verify that :term:`FiPy` works properly by
executing::

    $ python setup.py test

Depending on the packages you chose to install in :ref:`OPTIONALPACKAGES`
be sure to set the appropriate environment variables.  You can expect a few
errors if you did not install all of the recommended packages.

.. note::

   In order for Python_ to find the :term:`FiPy` modules, you will need to ensure
   that the base directory is added to your :envvar:`PYTHONPATH` environment
   variable, *e.g.*::

       $ setenv PYTHONPATH .:${PYTHONPATH}

   or::

       $ export PYTHONPATH=.:${PYTHONPATH}

If you chose to install the :mod:`scipy.weave` package, you should rerun the
tests with::

    $ python setup.py test --inline

A few tests will fail the first time as a result of the messages
output in the course of caching the compiled inline code, but a repeat
test should have no failures (although see "``repairing catalog by
removing key``" in the :ref:`FAQ`).

If :term:`FiPy` is configured for :ref:`PARALLEL`, you can run the tests 
on multiple processor cores with::

    $ mpirun -np {# of processors} python setup.py test

.. note::
   
   When running in parallel, there are two expected test failures in
   :mod:`examples.elphf.diffusion.mesh1D` and in
   :mod:`examples.diffusion.nthOrder.input4thOrder-line`. These failures are problems
   with those particular tests, not with the parallel mechanism itself.

.. _PARALLEL:

-------------------
Solving in Parallel
-------------------

:term:`FiPy` can use :term:`Trilinos` to solve equations in parallel, as 
long as they are defined on a "``Grid``" mesh 
(:class:`~fipy.meshes.numMesh.grid1D.Grid1D`, 
:class:`~fipy.meshes.numMesh.cylindricalGrid1D.CylindricalGrid1D`,
:class:`~fipy.meshes.numMesh.grid2D.Grid2D`,
:class:`~fipy.meshes.numMesh.cylindricalGrid2D.CylindricalGrid2D`, or
:class:`~fipy.meshes.numMesh.grid3D.Grid3D`). 

.. attention::

   :term:`Trilinos` *must* be compiled with MPI support.

.. attention::

   :term:`FiPy` requires `mpi4py <http://mpi4py.scipy.org/>`_ to work in parallel::

       $ easy_install mpi4py

.. note::

   A design wart presently *also* requires that :term:`PySparse` be
   installed. We hope to alleviate this requirement in a future release.

* It should not generally be necessary to change anything in your script.
  Simply invoke::

     $ mpirun -np {# of processors} python myScript.py

  instead of::

     $ python myScript.py

* To confirm that :term:`FiPy` and :term:`Trilinos` are properly 
  configured to solve in parallel, you can execute

  .. code-block:: python

     from fipy import parallel, Grid1D
     mesh = Grid1D(nx=10)
     print "%d cells on processor %d of %d" \
       % (mesh.getNumberOfCells(), parallel.procID, parallel.Nproc)

  (available as :file:`examples/parallel.py`) to check that :term:`FiPy` is
  distributing a mesh across processes as expected. E.g.::

     $ mpirun -np 3 python examples/parallel.py

  should print out::

     mpi4py: processor 0 of 3 :: PyTrilinos: processor 0 of 3 :: FiPy: 5 cells on processor 0 of 3
     mpi4py: processor 1 of 3 :: PyTrilinos: processor 1 of 3 :: FiPy: 7 cells on processor 1 of 3
     mpi4py: processor 2 of 3 :: PyTrilinos: processor 2 of 3 :: FiPy: 6 cells on processor 2 of 3

A complete list of the changes to FiPy's examples needed for parallel 
can be found at

  http://www.matforge.org/fipy/wiki/upgrade2_0examplesTo2_1

Most of the changes were required to ensure that :term:`FiPy` provides the
same literal output for both single and multiple processor solutions and
are not relevant to most "real" scripts. The two changes you *might* wish
to make to your own scripts are:

 * It is now preferable to use the 
   :class:`~fipy.solvers.DefaultAssymetricSolver` instead of the 
   :class:`~fipy.solvers.linearLUSolver.LinearLUSolver`. 

 * When solving in parallel, :term:`FiPy` essentially breaks the problem up 
   into separate sub-domains and solves them (somewhat) independently. 
   :term:`FiPy` generally "does the right thing", but if you find that you 
   need to do something with the entire solution, you can call
   ``var.``:meth:`~fipy.variables.cellVariable.CellVariable.getGlobalValue`.

:term:`Trilinos` solvers can be used to replace :term:`PySparse`
solvers. If both :term:`PySparse` and :term:`Trilinos` are present,
usage can be controlled by setting the :envvar:`FIPY_SOLVERS`
environment variable to ``Trilinos`` or ``Pysparse``, or by passing a
``--trilinos`` or ``--pysparse`` flag to the :term:`FiPy` script,
overriding the environment. In the absence of these indicators,
:term:`FiPy` will default to using :term:`PySparse` if it is
present. Using the ``--trilinos`` flag instructs :term:`FiPy` to
construct matrices using :term:`PySparse`, but solve them using
:term:`Trilinos`. To avoid the :term:`PySparse` requirement, use the
``--no-pysparse`` flag in place of the ``--trilinos`` flag. This will
both construct matrices and solve them with
:term:`Trilinos`. Unfortunately, :term:`Trilinos` tends to under
perform when compared to :term:`PySparse` during matrix construction.

.. note:: 

    :term:`Trilinos` solvers frequently give intermediate output that :term:`FiPy` cannot
    suppress. The most commonly encountered messages are:

     ``Gen_Prolongator warning : Max eigen <= 0.0``:
        which is not significant to :term:`FiPy`.

     ``Aztec status AZ_loss: loss of precision``:
        which indicates that there was some difficulty in solving the
        problem to the requested tolerance due to precision limitations,
        but usually does not prevent the solver from finding an adequate
        solution.

     ``Aztec status AZ_ill_cond: GMRES hessenberg ill-conditioned``:
        which indicates that GMRES is having trouble with the problem, and
        may indicate that trying a different solver or preconditioner may
        give more accurate results if GMRES fails.

     ``Aztec status AZ_breakdown: numerical breakdown``
        which usually indicates serious problems solving the equation which
        forced the solver to stop before reaching an adequate solution.
        Different solvers, different preconditioners, or a less restrictive
        tolerance may help.


.. _sec:UsingFiPy:

.. _RunningUnderPython3:

----------------------
Running under Python 3     
----------------------

It is possible to run :term:`FiPy` scripts under Python 3, but you must 
convert FiPy's code before you can do so. From within the main 
:term:`FiPy` directory::

    $ 2to3 --write .
    $ 2to3 --write --doctests_only .

You can expect some harmless warnings and non-terminal errors from this conversion.

The minimal prerequisites are:

 * NumPy version 1.5 or greater
 * SciPy version 0.9 or greater
 * Matplotlib version 1.2 or greater (this hasn't been released yet, and 
   we haven't been able to successfully test the 
   :mod:`~.fipy.viewers.matplotlibViewer` classes with their development 
   code.

There are three known failures in FiPy's test suite under Python 3.

 * `RuntimeError: Factor is exactly singular` in fipy/terms/unaryTerm.py. 
   This is a SciPy solver failure not limited to Py3k.
 * :class:`~fipy.viewers.vtkViewer.vtkCellViewer.VTKCellViewer` and 
   :class:`~fipy.viewers.vtkViewer.vtkFaceViewer.VTKFaceViewer` due to lack of 
   `enthought.tvtk.api` in Py3k.

Manual
======

You can view the manual online at <http://www.ctcms.nist.gov/fipy> or you 
can `download the latest manual`_ from 
<http://matforge.org/fipy/wiki/FiPyManual>. Alternatively,
it may be possible to build a fresh copy by issuing the following
command in the base directory::

    $ python setup.py build_docs --pdf --html

.. note::

   This mechanism is intended primarily for the developers. At a minimum, 
   you will need a development version of `Sphinx 1.0
   <http://sphinx.pocoo.org/latest>`_, plus all of its prerequisites.

.. _download the latest manual:  http://matforge.org/fipy/wiki/FiPyManual
